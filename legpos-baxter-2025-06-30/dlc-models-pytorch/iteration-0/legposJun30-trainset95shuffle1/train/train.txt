2025-06-30 18:59:45 Training with configuration:
2025-06-30 18:59:45 data:
2025-06-30 18:59:45   bbox_margin: 20
2025-06-30 18:59:45   colormode: RGB
2025-06-30 18:59:45   inference:
2025-06-30 18:59:45     normalize_images: True
2025-06-30 18:59:45     auto_padding:
2025-06-30 18:59:45       pad_width_divisor: 32
2025-06-30 18:59:45       pad_height_divisor: 32
2025-06-30 18:59:45   train:
2025-06-30 18:59:45     affine:
2025-06-30 18:59:45       p: 0.5
2025-06-30 18:59:45       rotation: 30
2025-06-30 18:59:45       scaling: [0.5, 1.25]
2025-06-30 18:59:45       translation: 0
2025-06-30 18:59:45     crop_sampling:
2025-06-30 18:59:45       width: 448
2025-06-30 18:59:45       height: 448
2025-06-30 18:59:45       max_shift: 0.1
2025-06-30 18:59:45       method: hybrid
2025-06-30 18:59:45     gaussian_noise: 12.75
2025-06-30 18:59:45     motion_blur: True
2025-06-30 18:59:45     normalize_images: True
2025-06-30 18:59:45 device: auto
2025-06-30 18:59:45 metadata:
2025-06-30 18:59:45   project_path: /content/drive/MyDrive/legpos-baxter-2025-06-30
2025-06-30 18:59:45   pose_config_path: /content/drive/MyDrive/legpos-baxter-2025-06-30/dlc-models-pytorch/iteration-0/legposJun30-trainset95shuffle1/train/pytorch_config.yaml
2025-06-30 18:59:45   bodyparts: ['toe']
2025-06-30 18:59:45   unique_bodyparts: []
2025-06-30 18:59:45   individuals: ['animal']
2025-06-30 18:59:45   with_identity: None
2025-06-30 18:59:45 method: bu
2025-06-30 18:59:45 model:
2025-06-30 18:59:45   backbone:
2025-06-30 18:59:45     type: HRNet
2025-06-30 18:59:45     model_name: hrnet_w48
2025-06-30 18:59:45     freeze_bn_stats: False
2025-06-30 18:59:45     freeze_bn_weights: False
2025-06-30 18:59:45     interpolate_branches: True
2025-06-30 18:59:45     increased_channel_count: False
2025-06-30 18:59:45   backbone_output_channels: 720
2025-06-30 18:59:45   heads:
2025-06-30 18:59:45     bodypart:
2025-06-30 18:59:45       type: DEKRHead
2025-06-30 18:59:45       weight_init: dekr
2025-06-30 18:59:45       target_generator:
2025-06-30 18:59:45         type: DEKRGenerator
2025-06-30 18:59:45         num_joints: 1
2025-06-30 18:59:45         pos_dist_thresh: 17
2025-06-30 18:59:45         bg_weight: 0.1
2025-06-30 18:59:45       criterion:
2025-06-30 18:59:45         heatmap:
2025-06-30 18:59:45           type: DEKRHeatmapLoss
2025-06-30 18:59:45           weight: 1
2025-06-30 18:59:45         offset:
2025-06-30 18:59:45           type: DEKROffsetLoss
2025-06-30 18:59:45           weight: 0.03
2025-06-30 18:59:45       predictor:
2025-06-30 18:59:45         type: DEKRPredictor
2025-06-30 18:59:45         apply_sigmoid: False
2025-06-30 18:59:45         use_heatmap: False
2025-06-30 18:59:45         clip_scores: True
2025-06-30 18:59:45         num_animals: 1
2025-06-30 18:59:45         keypoint_score_type: combined
2025-06-30 18:59:45         max_absorb_distance: 75
2025-06-30 18:59:45         nms_threshold: 0.05
2025-06-30 18:59:45         apply_pose_nms: True
2025-06-30 18:59:45       heatmap_config:
2025-06-30 18:59:45         channels: [720, 48, 2]
2025-06-30 18:59:45         num_blocks: 1
2025-06-30 18:59:45         dilation_rate: 1
2025-06-30 18:59:45         final_conv_kernel: 1
2025-06-30 18:59:45       offset_config:
2025-06-30 18:59:45         channels: [720, 15, 1]
2025-06-30 18:59:45         num_offset_per_kpt: 15
2025-06-30 18:59:45         num_blocks: 2
2025-06-30 18:59:45         dilation_rate: 1
2025-06-30 18:59:45         final_conv_kernel: 1
2025-06-30 18:59:45 net_type: dekr_w48
2025-06-30 18:59:45 runner:
2025-06-30 18:59:45   type: PoseTrainingRunner
2025-06-30 18:59:45   gpus: [0]
2025-06-30 18:59:45   key_metric: test.mAP
2025-06-30 18:59:45   key_metric_asc: True
2025-06-30 18:59:45   eval_interval: 10
2025-06-30 18:59:45   optimizer:
2025-06-30 18:59:45     type: AdamW
2025-06-30 18:59:45     params:
2025-06-30 18:59:45       lr: 0.0005
2025-06-30 18:59:45   scheduler:
2025-06-30 18:59:45     type: LRListScheduler
2025-06-30 18:59:45     params:
2025-06-30 18:59:45       lr_list: [[0.0001], [1e-05]]
2025-06-30 18:59:45       milestones: [90, 120]
2025-06-30 18:59:45   snapshots:
2025-06-30 18:59:45     max_snapshots: 5
2025-06-30 18:59:45     save_epochs: 5
2025-06-30 18:59:45     save_optimizer_state: False
2025-06-30 18:59:45   precision: amp
2025-06-30 18:59:45 train_settings:
2025-06-30 18:59:45   batch_size: 8
2025-06-30 18:59:45   dataloader_workers: 0
2025-06-30 18:59:45   dataloader_pin_memory: False
2025-06-30 18:59:45   display_iters: 300
2025-06-30 18:59:45   epochs: 100
2025-06-30 18:59:45   seed: 42
2025-06-30 18:59:45 with_center_keypoints: True
2025-06-30 18:59:46 Loading pretrained weights from Hugging Face hub (timm/hrnet_w48.ms_in1k)
2025-06-30 18:59:48 [timm/hrnet_w48.ms_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-06-30 18:59:48 Unexpected keys (downsamp_modules.0.0.bias, downsamp_modules.0.0.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.num_batches_tracked, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.weight, downsamp_modules.1.0.bias, downsamp_modules.1.0.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.weight, downsamp_modules.2.0.bias, downsamp_modules.2.0.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.num_batches_tracked, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.weight, final_layer.0.bias, final_layer.0.weight, final_layer.1.bias, final_layer.1.num_batches_tracked, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.weight, incre_modules.0.0.bn1.bias, incre_modules.0.0.bn1.num_batches_tracked, incre_modules.0.0.bn1.running_mean, incre_modules.0.0.bn1.running_var, incre_modules.0.0.bn1.weight, incre_modules.0.0.bn2.bias, incre_modules.0.0.bn2.num_batches_tracked, incre_modules.0.0.bn2.running_mean, incre_modules.0.0.bn2.running_var, incre_modules.0.0.bn2.weight, incre_modules.0.0.bn3.bias, incre_modules.0.0.bn3.num_batches_tracked, incre_modules.0.0.bn3.running_mean, incre_modules.0.0.bn3.running_var, incre_modules.0.0.bn3.weight, incre_modules.0.0.conv1.weight, incre_modules.0.0.conv2.weight, incre_modules.0.0.conv3.weight, incre_modules.0.0.downsample.0.weight, incre_modules.0.0.downsample.1.bias, incre_modules.0.0.downsample.1.num_batches_tracked, incre_modules.0.0.downsample.1.running_mean, incre_modules.0.0.downsample.1.running_var, incre_modules.0.0.downsample.1.weight, incre_modules.1.0.bn1.bias, incre_modules.1.0.bn1.num_batches_tracked, incre_modules.1.0.bn1.running_mean, incre_modules.1.0.bn1.running_var, incre_modules.1.0.bn1.weight, incre_modules.1.0.bn2.bias, incre_modules.1.0.bn2.num_batches_tracked, incre_modules.1.0.bn2.running_mean, incre_modules.1.0.bn2.running_var, incre_modules.1.0.bn2.weight, incre_modules.1.0.bn3.bias, incre_modules.1.0.bn3.num_batches_tracked, incre_modules.1.0.bn3.running_mean, incre_modules.1.0.bn3.running_var, incre_modules.1.0.bn3.weight, incre_modules.1.0.conv1.weight, incre_modules.1.0.conv2.weight, incre_modules.1.0.conv3.weight, incre_modules.1.0.downsample.0.weight, incre_modules.1.0.downsample.1.bias, incre_modules.1.0.downsample.1.num_batches_tracked, incre_modules.1.0.downsample.1.running_mean, incre_modules.1.0.downsample.1.running_var, incre_modules.1.0.downsample.1.weight, incre_modules.2.0.bn1.bias, incre_modules.2.0.bn1.num_batches_tracked, incre_modules.2.0.bn1.running_mean, incre_modules.2.0.bn1.running_var, incre_modules.2.0.bn1.weight, incre_modules.2.0.bn2.bias, incre_modules.2.0.bn2.num_batches_tracked, incre_modules.2.0.bn2.running_mean, incre_modules.2.0.bn2.running_var, incre_modules.2.0.bn2.weight, incre_modules.2.0.bn3.bias, incre_modules.2.0.bn3.num_batches_tracked, incre_modules.2.0.bn3.running_mean, incre_modules.2.0.bn3.running_var, incre_modules.2.0.bn3.weight, incre_modules.2.0.conv1.weight, incre_modules.2.0.conv2.weight, incre_modules.2.0.conv3.weight, incre_modules.2.0.downsample.0.weight, incre_modules.2.0.downsample.1.bias, incre_modules.2.0.downsample.1.num_batches_tracked, incre_modules.2.0.downsample.1.running_mean, incre_modules.2.0.downsample.1.running_var, incre_modules.2.0.downsample.1.weight, incre_modules.3.0.bn1.bias, incre_modules.3.0.bn1.num_batches_tracked, incre_modules.3.0.bn1.running_mean, incre_modules.3.0.bn1.running_var, incre_modules.3.0.bn1.weight, incre_modules.3.0.bn2.bias, incre_modules.3.0.bn2.num_batches_tracked, incre_modules.3.0.bn2.running_mean, incre_modules.3.0.bn2.running_var, incre_modules.3.0.bn2.weight, incre_modules.3.0.bn3.bias, incre_modules.3.0.bn3.num_batches_tracked, incre_modules.3.0.bn3.running_mean, incre_modules.3.0.bn3.running_var, incre_modules.3.0.bn3.weight, incre_modules.3.0.conv1.weight, incre_modules.3.0.conv2.weight, incre_modules.3.0.conv3.weight, incre_modules.3.0.downsample.0.weight, incre_modules.3.0.downsample.1.bias, incre_modules.3.0.downsample.1.num_batches_tracked, incre_modules.3.0.downsample.1.running_mean, incre_modules.3.0.downsample.1.running_var, incre_modules.3.0.downsample.1.weight, classifier.bias, classifier.weight) found while loading pretrained weights. This may be expected if model is being adapted.
2025-06-30 18:59:49 Data Transforms:
2025-06-30 18:59:49   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-06-30 18:59:49   Validation: Compose([
  PadIfNeeded(always_apply=False, p=1.0, min_height=None, min_width=None, pad_height_divisor=32, pad_width_divisor=32, position=PositionType.RANDOM, border_mode=4, value=None, mask_value=None),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-06-30 18:59:59 Using 176 images and 10 for testing
2025-06-30 18:59:59 
Starting pose model training...
--------------------------------------------------
2025-06-30 19:03:02 Epoch 1/100 (lr=0.0005), train loss 0.00159
2025-06-30 19:03:22 Epoch 2/100 (lr=0.0005), train loss 0.00133
2025-06-30 19:03:41 Epoch 3/100 (lr=0.0005), train loss 0.00108
2025-06-30 19:04:01 Epoch 4/100 (lr=0.0005), train loss 0.00103
2025-06-30 19:04:22 Epoch 5/100 (lr=0.0005), train loss 0.00084
2025-06-30 19:04:41 Epoch 6/100 (lr=0.0005), train loss 0.00077
2025-06-30 19:05:01 Epoch 7/100 (lr=0.0005), train loss 0.00077
2025-06-30 19:05:21 Epoch 8/100 (lr=0.0005), train loss 0.00083
2025-06-30 19:05:40 Epoch 9/100 (lr=0.0005), train loss 0.00077
2025-06-30 19:06:00 Training for epoch 10 done, starting evaluation
2025-06-30 19:06:12 Epoch 10/100 (lr=0.0005), train loss 0.00075, valid loss 0.00061
2025-06-30 19:06:12 Model performance:
2025-06-30 19:06:12   metrics/test.rmse:            nan
2025-06-30 19:06:12   metrics/test.rmse_pcutoff:    nan
2025-06-30 19:06:12   metrics/test.mAP:            0.00
2025-06-30 19:06:12   metrics/test.mAR:            0.00
2025-06-30 19:06:32 Epoch 11/100 (lr=0.0005), train loss 0.00068
2025-06-30 19:06:52 Epoch 12/100 (lr=0.0005), train loss 0.00068
2025-06-30 19:07:12 Epoch 13/100 (lr=0.0005), train loss 0.00067
2025-06-30 19:07:32 Epoch 14/100 (lr=0.0005), train loss 0.00072
2025-06-30 19:07:53 Epoch 15/100 (lr=0.0005), train loss 0.00065
2025-06-30 19:08:13 Epoch 16/100 (lr=0.0005), train loss 0.00064
2025-06-30 19:08:33 Epoch 17/100 (lr=0.0005), train loss 0.00061
2025-06-30 19:08:53 Epoch 18/100 (lr=0.0005), train loss 0.00056
2025-06-30 19:09:12 Epoch 19/100 (lr=0.0005), train loss 0.00052
2025-06-30 19:09:32 Training for epoch 20 done, starting evaluation
2025-06-30 19:09:34 Epoch 20/100 (lr=0.0005), train loss 0.00049, valid loss 0.00041
2025-06-30 19:09:34 Model performance:
2025-06-30 19:09:34   metrics/test.rmse:            nan
2025-06-30 19:09:34   metrics/test.rmse_pcutoff:    nan
2025-06-30 19:09:34   metrics/test.mAP:            0.00
2025-06-30 19:09:34   metrics/test.mAR:            0.00
2025-06-30 19:09:54 Epoch 21/100 (lr=0.0005), train loss 0.00047
2025-06-30 19:10:14 Epoch 22/100 (lr=0.0005), train loss 0.00046
2025-06-30 19:10:34 Epoch 23/100 (lr=0.0005), train loss 0.00042
2025-06-30 19:10:53 Epoch 24/100 (lr=0.0005), train loss 0.00043
2025-06-30 19:11:14 Epoch 25/100 (lr=0.0005), train loss 0.00041
2025-06-30 19:11:33 Epoch 26/100 (lr=0.0005), train loss 0.00040
2025-06-30 19:11:53 Epoch 27/100 (lr=0.0005), train loss 0.00033
2025-06-30 19:12:13 Epoch 28/100 (lr=0.0005), train loss 0.00039
2025-06-30 19:12:33 Epoch 29/100 (lr=0.0005), train loss 0.00036
2025-06-30 19:12:52 Training for epoch 30 done, starting evaluation
2025-06-30 19:12:55 Epoch 30/100 (lr=0.0005), train loss 0.00032, valid loss 0.00032
2025-06-30 19:12:55 Model performance:
2025-06-30 19:12:55   metrics/test.rmse:            nan
2025-06-30 19:12:55   metrics/test.rmse_pcutoff:    nan
2025-06-30 19:12:55   metrics/test.mAP:            0.00
2025-06-30 19:12:55   metrics/test.mAR:            0.00
2025-06-30 19:13:14 Epoch 31/100 (lr=0.0005), train loss 0.00030
2025-06-30 19:13:34 Epoch 32/100 (lr=0.0005), train loss 0.00039
2025-06-30 19:13:53 Epoch 33/100 (lr=0.0005), train loss 0.00035
2025-06-30 19:14:13 Epoch 34/100 (lr=0.0005), train loss 0.00031
2025-06-30 19:14:33 Epoch 35/100 (lr=0.0005), train loss 0.00033
2025-06-30 19:14:53 Epoch 36/100 (lr=0.0005), train loss 0.00033
2025-06-30 19:15:13 Epoch 37/100 (lr=0.0005), train loss 0.00031
2025-06-30 19:15:32 Epoch 38/100 (lr=0.0005), train loss 0.00025
2025-06-30 19:15:52 Epoch 39/100 (lr=0.0005), train loss 0.00027
2025-06-30 19:16:12 Training for epoch 40 done, starting evaluation
2025-06-30 19:16:14 Epoch 40/100 (lr=0.0005), train loss 0.00025, valid loss 0.00031
2025-06-30 19:16:14 Model performance:
2025-06-30 19:16:14   metrics/test.rmse:            nan
2025-06-30 19:16:14   metrics/test.rmse_pcutoff:    nan
2025-06-30 19:16:14   metrics/test.mAP:            0.00
2025-06-30 19:16:14   metrics/test.mAR:            0.00
2025-06-30 19:16:34 Epoch 41/100 (lr=0.0005), train loss 0.00034
2025-06-30 19:16:54 Epoch 42/100 (lr=0.0005), train loss 0.00027
2025-06-30 19:17:14 Epoch 43/100 (lr=0.0005), train loss 0.00028
2025-06-30 19:17:33 Epoch 44/100 (lr=0.0005), train loss 0.00029
2025-06-30 19:17:54 Epoch 45/100 (lr=0.0005), train loss 0.00028
2025-06-30 19:18:13 Epoch 46/100 (lr=0.0005), train loss 0.00025
2025-06-30 19:18:33 Epoch 47/100 (lr=0.0005), train loss 0.00030
2025-06-30 19:18:53 Epoch 48/100 (lr=0.0005), train loss 0.00027
2025-06-30 19:19:13 Epoch 49/100 (lr=0.0005), train loss 0.00022
2025-06-30 19:19:33 Training for epoch 50 done, starting evaluation
2025-06-30 19:19:35 Epoch 50/100 (lr=0.0005), train loss 0.00026, valid loss 0.00032
2025-06-30 19:19:35 Model performance:
2025-06-30 19:19:35   metrics/test.rmse:            nan
2025-06-30 19:19:35   metrics/test.rmse_pcutoff:    nan
2025-06-30 19:19:35   metrics/test.mAP:            0.00
2025-06-30 19:19:35   metrics/test.mAR:            0.00
2025-06-30 19:19:55 Epoch 51/100 (lr=0.0005), train loss 0.00023
